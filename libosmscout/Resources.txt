Import of germany.osm (~11G) from http://download.geofabrik.de/osm/.

As one can see the following steps are the relevant, most time-consuming
steps:

* Calculation the objects in areas index. "object in areas" calculation must be
  improved by improved the "point is area" algorithm.
* Parsing of the XML file. XML parsing could be improved by using
  the new binary OSM raw data format.
* Generation of ways.dat file. This is time consuming because the nodes of a way
  are resolved. Since data is too big to keep everything in memory and
  on-disk algortihm must be used, repeately scanning data files. Instead of this
  the nod eindex file could be used, but we need some performance tests first.

egrep -h "(^\+ Step|^   =>)" <logfile>

+ Step #1 - Preprocess...
   => 221.802 second(s)
+ Step #2 - Generating 'rawnode.idx'...
   => 29.594 second(s)
+ Step #3 - Generating 'rawway.idx'...
   => 8.851 second(s)
+ Step #4 - Generate 'relations.dat'...
   => 87.823 second(s)
+ Step #5 - Generating 'relation.idx'...
   => 1.502 second(s)
+ Step #6 - Generate 'nodes.dat'...
   => 22.687 second(s)
+ Step #7 - Generating 'node.idx'...
   => 1.005 second(s)
+ Step #8 - Generate 'ways.dat'...
   => 580.221 second(s)
+ Step #9 - Generating 'way.idx'...
   => 17.454 second(s)
+ Step #10 - Generate 'area.idx'...
   => 218.048 second(s)
+ Step #11 - Generate 'areanode.idx'...
   => 3.659 second(s)
+ Step #12 - Generate 'region.dat' and 'nameregion.idx'...
   => 1896.465 second(s)
+ Step #13 - Generate 'nodeuse.idx'...
   => 218.284 second(s)
+ Step #14 - Generate 'water.idx'...
   => 27.459 second(s)
   => 3334.879 second(s)

The following files have been generated (du --total -h *.idx *.dat):
67M	area.idx
8,0M	areanode.idx
1,5M	nameregion.idx
3,2M	node.idx
88M	nodeuse.idx
98M	rawnode.idx
15M	rawway.idx
204K	relation.idx
20K	water.idx
15M	way.idx
4,0K	bounding.dat
31M	nodes.dat
730M	rawnodes.dat
22M	rawrels.dat
331M	rawways.dat
21M	region.dat
110M	relations.dat
1,2M	wayblack.dat
635M	ways.dat
2,2G	insgesamt

Of these the following are necessary at application runtime:
67M	area.idx
8,0M	areanode.idx
1,5M	nameregion.idx
3,2M	node.idx
88M	nodeuse.idx
204K	relation.idx
20K	water.idx
15M	way.idx
4,0K	bounding.dat
31M	nodes.dat
21M	region.dat
110M	relations.dat
635M	ways.dat

Where the nodeuse.idx currently is only interesting for the internal routing
solution. However some code change is required to do not make the database
class require it. The water.idx is not finished and will likely increase
in future (not not in a way that it changes the overall calculation
drastically).

So the overall size required on disk for a gemrany map without routing
would be:

du --total -h area.idx areanode.idx bounding.dat nameregion.idx node.idx \
nodes.dat region.dat relation.idx relations.dat water.idx way.idx ways.dat

67M	area.idx
8,0M	areanode.idx
4,0K	bounding.dat
1,5M	nameregion.idx
3,2M	node.idx
31M	nodes.dat
21M	region.dat
204K	relation.idx
110M	relations.dat
20K	water.idx
15M	way.idx
635M	ways.dat
888M	insgesamt

Memory usage:
Open the germany map, search for Bonn, search for Dortmund
(top -b | grep <processname>):

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 7788 tim       20   0 1061m 148m  34m S    0  4.9   0:06.03 lt-TravelJinni
 9066 tim       20   0  987m 128m  37m S    0  4.2   0:09.55 lt-OSMScout

Most of the memory useage however comes from opening the data files using memory
maped files.

The same, if no memory maped files are used:

 9276 tim       20   0  219m 127m  13m S    0  4.2   0:02.97 lt-TravelJinni

This is the result of the internal statistics dump. Memory usage is rather
high (but was much higher in the past). There is not yet any real measurement
regarding optimal/minimal cache sizes, so possibly by just reducing the cache
sizes some memory can be saved.

Problem is not the in memory cache for nodes, ways/areas and relations but the
various indexes. The currently biggest index is the area node index and should
be next target for optimizations. After that most memory saving can be gained by
improving the NumericIndex that is used for accessing all date files. Possibly
using caching to hold only used index pages in memory is possible here, too.

The "node index use" index is only used for routing and should be made
optional.

nodes.dat entries: 12, memory 160960
Index node.idx: 120 entries, memory 3209208
ways.dat entries: 752, memory 250240
Index way.idx: 191 entries, memory 3200199
relations.dat entries: 755, memory 82440
Index relation.idx: 259 entries, memory 1600267
Node use cache entries: 0, memory 16
area.idx entries: 839, memory 293640
Area node index size 351882, memory 11039966
AdminRegion size 77176, locations size 0, memory 2160928
Node index use size 601636, memory usage 7219632

